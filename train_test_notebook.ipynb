{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTransGAN: Training and Prediction Notebook\n",
    "This notebook provides a comprehensive guide to training and using a neural network for converting low-light (INR) images to normal-light (RGB) images. The project is inspired by AI enhancement techniques and aims to improve visibility in low-light conditions for applications such as autonomous driving and surveillance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "The dataset consists of pairs of INR images (low-light) and corresponding RGB images (normal light). The `datasets/data_set.py` script is used to load and preprocess the data.\n",
    "\n",
    "### 1.1. Dataset Format\n",
    "\n",
    "The dataset should be organized as follows:\n",
    "\n",
    "```\n",
    "your_data_directory/\n",
    "    our485/  # Training data\n",
    "        high/  # Contains RGB images\n",
    "            image1.png\n",
    "            image2.jpg\n",
    "            ...\n",
    "        low/   # Contains INR images\n",
    "            image1.png\n",
    "            image2.jpg\n",
    "            ...\n",
    "    eval15/  # Testing data\n",
    "        high/\n",
    "            image1.png\n",
    "            image2.jpg\n",
    "            ...\n",
    "        low/\n",
    "            image1.png\n",
    "            image2.jpg\n",
    "            ...\n",
    "```\n",
    "\n",
    "### 1.2. Loading and Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from datasets.data_set import LowLightDataset\n",
    "\n",
    "# 1. Set the dataset directory\n",
    "data_dir = \"../datasets/LOLdataset\"  # Replace with your dataset path\n",
    "\n",
    "# 2. Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 3. Create dataset instance\n",
    "train_dataset = LowLightDataset(image_dir=data_dir, transform=transform, phase=\"train\")\n",
    "\n",
    "# 4. Access a sample\n",
    "low_img, high_img = train_dataset[0]\n",
    "\n",
    "# 5. Convert tensors to numpy arrays and rescale\n",
    "low_img_np = low_img.permute(1, 2, 0).numpy() * 0.5 + 0.5\n",
    "high_img_np = high_img.permute(1, 2, 0).numpy() * 0.5 + 0.5\n",
    "\n",
    "# 6. Display the images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(low_img_np)\n",
    "axes[0].set_title(\"Low-light (INR) Image\")\n",
    "axes[1].imshow(high_img_np)\n",
    "axes[1].set_title(\"Normal-light (RGB) Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition\n",
    "\n",
    "The core of the INR2RGB conversion is a Generator model, which attempts to transform the low-light INR image into a corresponding RGB image. A Discriminator (or Critic in WGAN) model is used to evaluate the quality of the generated images and provide feedback to the Generator during training.\n",
    "\n",
    "The models are defined in `models/base_mode.py`. The Generator uses RepViT blocks, SPPELAN, and other convolutional layers to extract features and generate the RGB image. The Discriminator (or Critic) uses Disconv layers to classify images as real or fake.\n",
    "\n",
    "### 2.1. Generator\n",
    "\n",
    "The Generator architecture consists of several convolutional blocks, upsampling layers, and concatenation operations. It takes an INR image as input and outputs an RGB image.\n",
    "\n",
    "### 2.2. Discriminator (or Critic)\n",
    "\n",
    "The Discriminator (or Critic) is a binary classifier that distinguishes between real RGB images and generated RGB images. It provides feedback to the Generator, guiding it to produce more realistic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.base_mode import Generator, Discriminator\n",
    "import torch\n",
    "\n",
    "# 1. Initialize the models\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Create Generator and Discriminator instances\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# 3. Print model summary\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Generator parameters: {count_parameters(generator):,}\")\n",
    "print(f\"Discriminator parameters: {count_parameters(discriminator):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the Model\n",
    "\n",
    "Now we'll set up the training process for the INR2RGB model. We'll use a GAN (Generative Adversarial Network) approach, where the Generator tries to produce realistic RGB images, and the Discriminator tries to distinguish between real and generated images.\n",
    "\n",
    "### 3.1. Setting up Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.loss import BCEBlurWithLogitsLoss, FocalLoss\n",
    "from torcheval.metrics.functional import peak_signal_noise_ratio\n",
    "from utils.misic import ssim\n",
    "\n",
    "# 1. Training parameters\n",
    "batch_size = 16\n",
    "num_epochs = 50  # 实际训练可能需要更多轮次，这里为了演示设置较小的值\n",
    "lr = 3.5e-4\n",
    "b1 = 0.5  # Adam优化器的beta1参数\n",
    "b2 = 0.999  # Adam优化器的beta2参数\n",
    "\n",
    "# 2. Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# 3. Create test dataset and loader\n",
    "test_dataset = LowLightDataset(image_dir=data_dir, transform=transform, phase=\"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# 4. Initialize optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# 5. Define loss functions\n",
    "adversarial_loss = BCEBlurWithLogitsLoss().to(device)  # 对抗损失\n",
    "pixel_loss = torch.nn.L1Loss().to(device)  # 像素级损失（L1损失）\n",
    "\n",
    "# 6. Set pixel loss weight (lambda)\n",
    "lambda_pixel = 100  # 像素损失的权重系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# 1. Initialize lists to store metrics\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "psnr_values = []\n",
    "ssim_values = []\n",
    "\n",
    "# 2. 启用混合精度训练\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 3. 学习率调度器\n",
    "class WarmupCosineScheduler:\n",
    "    def __init__(self, optimizer, warmup_epochs, total_epochs, min_lr=1e-6, warmup_start_lr=1e-7):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.total_epochs = total_epochs\n",
    "        self.min_lr = min_lr\n",
    "        self.warmup_start_lr = warmup_start_lr\n",
    "        self.base_lr = optimizer.param_groups[0]['lr']\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.current_epoch += 1\n",
    "        if self.current_epoch <= self.warmup_epochs:\n",
    "            # Warmup阶段：线性增加学习率\n",
    "            lr = self.warmup_start_lr + (self.base_lr - self.warmup_start_lr) * \
",
    "                (self.current_epoch / self.warmup_epochs)\n",
    "        else:\n",
    "            # 余弦退火阶段\n",
    "            progress = (self.current_epoch - self.warmup_epochs) / \
",
    "                (self.total_epochs - self.warmup_epochs)\n",
    "            lr = self.min_lr + (self.base_lr - self.min_lr) * \
",
    "                0.5 * (1 + np.cos(np.pi * progress))\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "# 4. 初始化学习率调度器\n",
    "warmup_epochs = int(num_epochs * 0.1)  # 使用总epochs的10%作为warmup\n",
    "scheduler_g = WarmupCosineScheduler(\n",
    "    optimizer=optimizer_G,\n",
    "    warmup_epochs=warmup_epochs,\n",
    "    total_epochs=num_epochs,\n",
    "    min_lr=lr * 0.001,\n",
    "    warmup_start_lr=lr * 0.0001\n",
    ")\n",
    "scheduler_d = WarmupCosineScheduler(\n",
    "    optimizer=optimizer_D,\n",
    "    warmup_epochs=warm