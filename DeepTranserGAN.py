'''
code by é»„å°æµ·  2025/2/19

è¿™æ˜¯ä¸€ä¸ªåŸºäºPyTorchçš„æ·±åº¦å­¦ä¹ é¡¹ç›®ï¼Œç”¨äºä½å…‰ç…§å›¾åƒå¢å¼ºã€‚
æ•°æ®é›†ç»“æ„ï¼š
- datasets
    - kitti_LOL
        - eval15
            - high
            - low
        - our485
            - high
            - low
- DeepTranserGAN



'''
import os
import time
import cv2
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.cuda.amp import autocast
from torch.utils.tensorboard.writer import SummaryWriter
from torch.utils.data import DataLoader
from torcheval.metrics.functional import peak_signal_noise_ratio
from torchvision import transforms
from tqdm import tqdm  # æ›´æ–°å¯¼å…¥ä»¥ä½¿ç”¨æ–°çš„autocast API

from datasets.data_set import LowLightDataset
from models.base_mode import Generator, Discriminator
from utils.misic import set_random_seed, get_opt, get_loss, ssim, model_structure, save_path


# æ·»åŠ  SpectralNorm å®ç°ï¼Œç”¨äºç¨³å®šåˆ¤åˆ«å™¨è®­ç»ƒ
def spectral_norm(module, name='weight', power_iterations=1):
    """
    å¯¹æ¨¡å—åº”ç”¨è°±å½’ä¸€åŒ–
    """
    if isinstance(module, (nn.Conv2d, nn.Linear)):
        original_method = module.forward

        u = torch.randn(module.weight.size(0), 1, requires_grad=False)
        u = u.to(module.weight.device)

        def _l2normalize(v):
            return v / (torch.norm(v) + 1e-12)

        def spectral_norm_forward(*args, **kwargs):
            weight = module.weight
            weight_mat = weight.view(weight.size(0), -1)

            for _ in range(power_iterations):
                v = _l2normalize(torch.matmul(weight_mat.t(), u))
                u.data = _l2normalize(torch.matmul(weight_mat, v))

            sigma = torch.dot(u.view(-1), torch.matmul(weight_mat, v).view(-1))
            weight = weight / sigma

            return original_method(*args, **kwargs)

        module.forward = spectral_norm_forward

    return module


# æ·»åŠ  SpectralNormConv2d ç±»ï¼Œç”¨äºæ›¿æ¢åˆ¤åˆ«å™¨ä¸­çš„å·ç§¯å±‚


class SpectralNormConv2d(nn.Module):

    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels,
                              kernel_size, stride, padding, bias=bias)
        self.conv = spectral_norm(self.conv)

    def forward(self, x):
        return self.conv(x)


# æ·»åŠ è‡ªå®šä¹‰çš„Warmupä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦å™¨
class WarmupCosineScheduler:

    def __init__(self, optimizer, warmup_epochs, total_epochs, min_lr=1e-6, warmup_start_lr=1e-7):
        self.optimizer = optimizer
        self.warmup_epochs = warmup_epochs
        self.total_epochs = total_epochs
        self.min_lr = min_lr
        self.warmup_start_lr = warmup_start_lr
        self.base_lr = optimizer.param_groups[0]['lr']
        self.current_epoch = 0

    def step(self):
        self.current_epoch += 1
        if self.current_epoch <= self.warmup_epochs:
            # Warmupé˜¶æ®µï¼šçº¿æ€§å¢åŠ å­¦ä¹ ç‡
            lr = self.warmup_start_lr + (self.base_lr - self.warmup_start_lr) * \
                (self.current_epoch / self.warmup_epochs)
        else:
            # ä½™å¼¦é€€ç«é˜¶æ®µ
            progress = (self.current_epoch - self.warmup_epochs) / \
                (self.total_epochs - self.warmup_epochs)
            lr = self.min_lr + (self.base_lr - self.min_lr) * \
                0.5 * (1 + np.cos(np.pi * progress))

        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr

    def state_dict(self):
        return {
            'current_epoch': self.current_epoch,
            'base_lr': self.base_lr,
            'warmup_epochs': self.warmup_epochs,
            'total_epochs': self.total_epochs,
            'min_lr': self.min_lr,
            'warmup_start_lr': self.warmup_start_lr
        }

    def load_state_dict(self, state_dict):
        self.current_epoch = state_dict['current_epoch']
        self.base_lr = state_dict['base_lr']
        self.warmup_epochs = state_dict['warmup_epochs']
        self.total_epochs = state_dict['total_epochs']
        self.min_lr = state_dict['min_lr']
        self.warmup_start_lr = state_dict['warmup_start_lr']


class BaseTrainer:

    def __init__(self, args, generator, discriminator=None, critic=None):
        self.args = args
        self.generator = generator
        self.discriminator = discriminator
        self.critic = critic
        self.device = torch.device('cpu')
        if args.device == 'cuda':
            self.device = torch.device(
                'cuda:0' if torch.cuda.is_available() else 'cpu')
        self.generator = self.generator.to(self.device)

        # åˆå§‹åŒ–ç”Ÿæˆå™¨æƒé‡
        self._initialize_weights(self.generator)

        if self.discriminator is not None:
            self.discriminator = self.discriminator.to(self.device)
            # åˆå§‹åŒ–åˆ¤åˆ«å™¨æƒé‡
            self._initialize_weights(self.discriminator)
            # åº”ç”¨è°±å½’ä¸€åŒ–åˆ°åˆ¤åˆ«å™¨
            self._apply_spectral_norm(self.discriminator)
        if self.critic is not None:
            self.critic = self.critic.to(self.device)
            # åˆå§‹åŒ–è¯„è®ºå™¨æƒé‡
            self._initialize_weights(self.critic)
            # åº”ç”¨è°±å½’ä¸€åŒ–åˆ°è¯„è®ºå™¨
            self._apply_spectral_norm(self.critic)

        # å¢å¼ºæ•°æ®å¢å¼º
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((256, 256)),
            transforms.RandomHorizontalFlip(p=0.5),  # éšæœºæ°´å¹³ç¿»è½¬
            transforms.RandomRotation(10),  # éšæœºæ—‹è½¬Â±10åº¦
            transforms.ColorJitter(brightness=0.1, contrast=0.1),  # äº®åº¦å’Œå¯¹æ¯”åº¦å˜åŒ–
            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),  # å°å¹…å¹³ç§»
            transforms.ToTensor(),
            # transforms.Normalize(
            #     (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # æ ‡å‡†åŒ–åˆ° [-1, 1]
        ])

        self.train_data = LowLightDataset(
            image_dir=args.data, transform=self.transform, phase="train")
        self.train_loader = DataLoader(self.train_data,
                                       batch_size=args.batch_size,
                                       num_workers=args.num_workers,
                                       shuffle=True,
                                       drop_last=True,
                                       pin_memory=True)  # å¯ç”¨pin_memoryåŠ é€Ÿæ•°æ®ä¼ è¾“

        # æµ‹è¯•æ•°æ®ä¸éœ€è¦å¢å¼ºï¼Œä½†éœ€è¦æ ‡å‡†åŒ–
        self.test_transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            # transforms.Normalize(
            #    (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # æ ‡å‡†åŒ–åˆ° [-1, 1]
        ])

        self.test_data = LowLightDataset(
            image_dir=args.data, transform=self.test_transform, phase="test")
        self.test_loader = DataLoader(self.test_data,
                                      batch_size=args.batch_size,
                                      num_workers=args.num_workers,
                                      shuffle=False,
                                      drop_last=False,
                                      pin_memory=True)

        # ä¼˜åŒ–å™¨åˆå§‹åŒ– - ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡
        self.g_optimizer, self.d_optimizer = get_opt(
            args, self.generator, self.discriminator)

        self.g_loss = get_loss(args.loss).to(
            self.device) if args.loss else nn.MSELoss().to(self.device)
        self.stable_loss = nn.L1Loss().to(self.device)

        # è·¯å¾„è®¾ç½®
        self.path = save_path(
            args.save_path) if args.resume == '' else args.resume
        self.log = SummaryWriter(
            log_dir=self.path, filename_suffix=str(args.epochs), flush_secs=180)

        # æ¨¡å‹ä¿å­˜ç­–ç•¥
        self.best_psnr = 0.0
        self.best_ssim = 0.0
        self.patience = args.patience if hasattr(args, 'patience') else 10
        self.patience_counter = 0
        self.eval_interval = 5  # æ¯5ä¸ªepochè¯„ä¼°ä¸€æ¬¡

        # å­¦ä¹ ç‡è°ƒåº¦ - ä½¿ç”¨Warmupå’Œä½™å¼¦é€€ç«
        warmup_epochs = int(args.epochs * 0.1)  # ä½¿ç”¨æ€»epochsçš„10%ä½œä¸ºwarmup
        self.scheduler_g = WarmupCosineScheduler(optimizer=self.g_optimizer,
                                                 warmup_epochs=warmup_epochs,
                                                 total_epochs=args.epochs,
                                                 min_lr=args.lr * 0.001,
                                                 warmup_start_lr=args.lr * 0.0001)
        if self.d_optimizer is not None:
            self.scheduler_d = WarmupCosineScheduler(optimizer=self.d_optimizer,
                                                     warmup_epochs=warmup_epochs,
                                                     total_epochs=args.epochs,
                                                     min_lr=args.lr * 0.001,
                                                     warmup_start_lr=args.lr * 0.0001)
        else:
            self.scheduler_d = None

        # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
        self.grad_accum_steps = args.grad_accum_steps if hasattr(
            args, 'grad_accum_steps') else 1

        # æ ‡ç­¾å¹³æ»‘å‚æ•°
        self.label_smoothing = 0.1

        # æ¢¯åº¦æƒ©ç½šæƒé‡
        self.lambda_gp = 10

        # æ·»åŠ å™ªå£°åˆ°åˆ¤åˆ«å™¨è¾“å…¥
        self.noise_factor = 0.05

        # ä¸¤æ—¶é—´å°ºåº¦æ›´æ–°è§„åˆ™ (TTUR)
        self.d_updates_per_g = 2  # æ¯è®­ç»ƒä¸€æ¬¡ç”Ÿæˆå™¨ï¼Œè®­ç»ƒåˆ¤åˆ«å™¨çš„æ¬¡æ•°

        # ç¡®ä¿è·¯å¾„å­˜åœ¨
        if self.args.resume == '':
            os.makedirs(os.path.join(self.path, 'generator'), exist_ok=True)
            if self.discriminator is not None:
                os.makedirs(os.path.join(
                    self.path, 'discriminator'), exist_ok=True)
            if self.critic is not None:
                os.makedirs(os.path.join(self.path, 'critic'), exist_ok=True)

        self.train_log = self.path + '/log.txt'
        self.args_dict = args.__dict__
        self.epoch = 0
        self.Ssim = [0.]
        self.PSN = [0.]

        # è®°å½•è®­ç»ƒé…ç½®
        self._log_training_config()

        # å¯¼å…¥ rich åº“ç”¨äºç¾åŒ–æ˜¾ç¤º
        try:
            from rich.console import Console
            from rich.table import Table
            from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn, TimeRemainingColumn
            self.rich_available = True
            self.console = Console()
        except ImportError:
            self.rich_available = False
            print("æç¤º: å®‰è£… rich åº“å¯ä»¥è·å¾—æ›´ç¾è§‚çš„è®­ç»ƒæ˜¾ç¤ºæ•ˆæœ (pip install rich)")

        # ç®€åŒ–æŸå¤±å‡½æ•°é…ç½®
        self.pixel_loss_weight = 1.0  # åƒç´ æŸå¤±æƒé‡

        # æ·»åŠ æ¢¯åº¦ç¼©æ”¾å› å­ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        self.gradient_scale = 0.1

        # æ·»åŠ å­¦ä¹ ç‡è°ƒæ•´å› å­
        self.lr_decay_factor = 0.5
        self.lr_decay_patience = 5
        self.lr_decay_counter = 0

        # æ·»åŠ æ¢¯åº¦è£å‰ªå€¼
        self.grad_clip_discriminator = 2.0
        self.grad_clip_generator = 1.0

    def _log_training_config(self):
        """è®°å½•è®­ç»ƒé…ç½®åˆ°æ—¥å¿—æ–‡ä»¶"""
        with open(self.train_log, "a") as f:
            f.write("=== Training Configuration ===\n")
            for key, value in self.args_dict.items():
                f.write(f"{key}: {value}\n")
            f.write("============================\n\n")

    def load_checkpoint(self):
        if self.args.resume != '':
            # åŠ è½½ç”Ÿæˆå™¨
            g_path_checkpoint = os.path.join(
                self.args.resume, 'generator/last.pt')
            if os.path.exists(g_path_checkpoint):
                try:
                    # First try loading with weights_only=True (safer)
                    g_checkpoint = torch.load(
                        g_path_checkpoint, map_location=self.device, weights_only=True)
                except Exception as e:
                    print(
                        "Warning: Failed to load with weights_only=True, attempting legacy loading...")
                    # If that fails, try the legacy loading method
                    g_checkpoint = torch.load(
                        g_path_checkpoint, map_location=self.device, weights_only=False)

                self.generator.load_state_dict(g_checkpoint['net'])
                self.g_optimizer.load_state_dict(g_checkpoint['optimizer'])
                self.epoch = g_checkpoint['epoch']
                if 'best_psnr' in g_checkpoint:
                    self.best_psnr = g_checkpoint['best_psnr']
                if 'best_ssim' in g_checkpoint:
                    self.best_ssim = g_checkpoint['best_ssim']
                if 'scheduler' in g_checkpoint:
                    self.scheduler_g.load_state_dict(g_checkpoint['scheduler'])
            else:
                raise FileNotFoundError(
                    f"Generator checkpoint {g_path_checkpoint} not found.")

            # åŠ è½½åˆ¤åˆ«å™¨æˆ–è¯„è®ºå™¨
            d_path_checkpoint = os.path.join(
                self.args.resume, 'discriminator/last.pt') if \
                self.discriminator else os.path.join(self.args.resume, 'critic/last.pt')
            if os.path.exists(d_path_checkpoint):
                try:
                    # First try loading with weights_only=True (safer)
                    d_checkpoint = torch.load(
                        d_path_checkpoint, map_location=self.device, weights_only=True)
                except Exception as e:
                    print(
                        "Warning: Failed to load with weights_only=True, attempting legacy loading...")
                    # If that fails, try the legacy loading method
                    d_checkpoint = torch.load(
                        d_path_checkpoint, map_location=self.device, weights_only=False)

                if self.discriminator:
                    self.discriminator.load_state_dict(d_checkpoint['net'])
                elif self.critic:
                    self.critic.load_state_dict(d_checkpoint['net'])
                if self.d_optimizer is not None:
                    self.d_optimizer.load_state_dict(d_checkpoint['optimizer'])
                    if 'scheduler' in d_checkpoint and self.scheduler_d is not None:
                        self.scheduler_d.load_state_dict(
                            d_checkpoint['scheduler'])
            else:
                raise FileNotFoundError(
                    f"Discriminator/Critic checkpoint {d_path_checkpoint} not found.")

            print(f'Continuing training from epoch: {self.epoch + 1}')
            self.path = self.args.resume
            self.args.resume = ''

    def save_checkpoint(self, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œå¯é€‰æ‹©æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹"""
        save_path = os.path.join(
            self.path, 'generator', 'best.pt' if is_best else 'last.pt')

        # ä¿å­˜ç”Ÿæˆå™¨
        g_checkpoint = {
            'net': self.generator.state_dict(),
            'optimizer': self.g_optimizer.state_dict(),
            'epoch': self.epoch,
            'best_psnr': self.best_psnr,
            'best_ssim': self.best_ssim,
            'scheduler': self.scheduler_g.state_dict()
        }
        torch.save(g_checkpoint, save_path)

        # ä¿å­˜åˆ¤åˆ«å™¨æˆ–è¯„è®ºå™¨
        d_save_path = os.path.join(self.path, 'discriminator' if self.discriminator else 'critic',
                                   'best.pt' if is_best else 'last.pt')

        d_net_state = None
        if self.discriminator is not None:
            d_net_state = self.discriminator.state_dict()
        elif self.critic is not None:
            d_net_state = self.critic.state_dict()

        if d_net_state is not None and self.d_optimizer is not None:
            d_checkpoint = {
                'net': d_net_state,
                'optimizer': self.d_optimizer.state_dict(),
                'epoch': self.epoch,
            }
            if self.scheduler_d is not None:
                d_checkpoint['scheduler'] = self.scheduler_d.state_dict()

            torch.save(d_checkpoint, d_save_path)

    def log_message(self, message):
        print(message)
        with open(self.train_log, "a") as f:
            f.write(f"{message}\n")

    def write_log(self, epoch, gen_loss, dis_loss, d_x, d_g_z1, d_g_z2):
        train_log_txt_formatter = (
            '{time_str} \t [Epoch] \t {epoch:03d} \t [gLoss] \t {gloss_str} \t [dLoss] \t {dloss_str} \t {Dx_str} \t ['
            'Dgz0] \t {Dgz0_str} \t [Dgz1] \t {Dgz1_str}\n')
        to_write = train_log_txt_formatter.format(time_str=time.strftime("%Y_%m_%d_%H:%M:%S"),
                                                  epoch=epoch + 1,
                                                  gloss_str=" ".join(
                                                      ["{:4f}".format(np.mean(gen_loss))]),
                                                  dloss_str=" ".join(
                                                      ["{:4f}".format(np.mean(dis_loss))]),
                                                  Dx_str=" ".join(
                                                      ["{:4f}".format(d_x)]),
                                                  Dgz0_str=" ".join(
                                                      ["{:4f}".format(d_g_z1)]),
                                                  Dgz1_str=" ".join(["{:4f}".format(d_g_z2)]))
        with open(self.train_log, "a") as f:
            f.write(to_write)

    def visualize_results(self, epoch, gen_loss, dis_loss, high_images, low_images, fake):
        self.log.add_scalar('generation loss', np.mean(gen_loss), epoch + 1)
        self.log.add_scalar('discrimination loss',
                            np.mean(dis_loss), epoch + 1)
        self.log.add_scalar('learning rate', self.g_optimizer.state_dict()[
                            'param_groups'][0]['lr'], epoch + 1)
        self.log.add_images('real', high_images, epoch + 1)
        self.log.add_images('input', low_images, epoch + 1)
        self.log.add_images('fake', fake, epoch + 1)

    def evaluate_model(self):
        with torch.no_grad():
            self.log_message(
                f"Evaluating the generator model at epoch {self.epoch + 1}")
            self.generator.eval()
            if self.discriminator:
                self.discriminator.eval()
            elif self.critic:
                self.critic.eval()

            Ssim = []
            PSN = []

            for i, (low_images, high_images) in enumerate(self.test_loader):
                low_images = low_images.to(self.device)
                high_images = high_images.to(self.device)

                # ç”Ÿæˆå¢å¼ºå›¾åƒ
                fake_eval = self.generator(low_images)

                # è®¡ç®—SSIMå’ŒPSNR
                ssim_value = ssim(fake_eval, high_images).item()
                psnr_value = peak_signal_noise_ratio(
                    fake_eval, high_images).item()

                Ssim.append(ssim_value)
                PSN.append(psnr_value)

            # è®¡ç®—å¹³å‡æŒ‡æ ‡
            avg_ssim = np.mean(Ssim)
            avg_psnr = np.mean(PSN)

            # è®°å½•åˆ°TensorBoard
            self.log.add_scalar('SSIM', avg_ssim, self.epoch + 1)
            self.log.add_scalar('PSNR', avg_psnr, self.epoch + 1)

            self.log_message(
                f"Model SSIM: {avg_ssim:.4f}  PSNR: {avg_psnr:.4f}")

            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
            is_best = False
            if avg_psnr > self.best_psnr:
                self.log_message(
                    f"New best PSNR: {avg_psnr:.4f} (previous: {self.best_psnr:.4f})")
                self.best_psnr = avg_psnr
                is_best = True
                self.patience_counter = 0
            elif avg_ssim > self.best_ssim:
                self.log_message(
                    f"New best SSIM: {avg_ssim:.4f} (previous: {self.best_ssim:.4f})")
                self.best_ssim = avg_ssim
                is_best = True
                self.patience_counter = 0
            else:
                self.patience_counter += 1
                self.log_message(
                    f"No improvement. Patience: {self.patience_counter}/{self.patience}")

            # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜æ£€æŸ¥ç‚¹
            if is_best:
                self.save_checkpoint(is_best=True)

            # æ£€æŸ¥æ—©åœ
            if self.patience_counter >= self.patience:
                self.log_message("Early stopping triggered.")
                return True  # åœæ­¢è®­ç»ƒ

            return False

    def create_rich_progress(self):
        """åˆ›å»ºç¾åŒ–çš„è¿›åº¦æ¡"""
        if not self.rich_available:
            return None

        from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn, TimeRemainingColumn

        return Progress(TextColumn("[bold blue]{task.description}"),
                        BarColumn(bar_width=40),
                        TaskProgressColumn(),
                        TextColumn("â€¢"),
                        TimeElapsedColumn(),
                        TextColumn("â€¢"),
                        TimeRemainingColumn(),
                        expand=True)

    def print_epoch_summary(self, epoch, gen_loss, dis_loss, metrics=None):
        """æ‰“å°æ¯ä¸ªepochç»“æŸæ—¶çš„è®­ç»ƒæ‘˜è¦"""
        metrics = metrics or {}

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_gen_loss = sum(gen_loss) / len(gen_loss) if gen_loss else 0
        avg_dis_loss = sum(dis_loss) / len(dis_loss) if dis_loss else 0

        if self.rich_available:
            from rich.table import Table

            # åˆ›å»ºè¡¨æ ¼
            table = Table(
                title=f"ğŸ“Š è®­ç»ƒæ‘˜è¦ - Epoch {epoch + 1}/{self.args.epochs}", expand=True)

            # æ·»åŠ åˆ—
            table.add_column("ç±»åˆ«", style="cyan")
            table.add_column("æŒ‡æ ‡", style="magenta")
            table.add_column("æ•°å€¼", style="green")

            # æ·»åŠ æŸå¤±æ•°æ®
            table.add_row("æŸå¤±", "ç”Ÿæˆå™¨å¹³å‡æŸå¤±", f"{avg_gen_loss:.6f}")
            table.add_row("æŸå¤±", "åˆ¤åˆ«å™¨å¹³å‡æŸå¤±", f"{avg_dis_loss:.6f}")

            # æ·»åŠ å­¦ä¹ ç‡æ•°æ®
            if hasattr(self, 'g_optimizer') and self.g_optimizer is not None:
                g_lr = self.g_optimizer.param_groups[0]['lr']
                table.add_row("å­¦ä¹ ç‡", "ç”Ÿæˆå™¨", f"{g_lr:.6f}")
            if hasattr(self, 'd_optimizer') and self.d_optimizer is not None:
                d_lr = self.d_optimizer.param_groups[0]['lr']
                table.add_row("å­¦ä¹ ç‡", "åˆ¤åˆ«å™¨/è¯„è®ºå™¨", f"{d_lr:.6f}")

            # æ·»åŠ å…¶ä»–æŒ‡æ ‡
            for key, value in metrics.items():
                table.add_row("æŒ‡æ ‡", key, f"{value}" if isinstance(
                    value, str) else f"{value:.4f}")

            # æ·»åŠ å†…å­˜ä½¿ç”¨æƒ…å†µ
            if torch.cuda.is_available():
                table.add_row(
                    "GPUå†…å­˜", "å·²åˆ†é…", f"{torch.cuda.memory_allocated() / 1024**2:.2f} MB")
                table.add_row(
                    "GPUå†…å­˜", "ç¼“å­˜", f"{torch.cuda.memory_reserved() / 1024**2:.2f} MB")
                table.add_row(
                    "GPUå†…å­˜", "æœ€å¤§åˆ†é…", f"{torch.cuda.max_memory_allocated() / 1024**2:.2f} MB")

            # æ‰“å°è¡¨æ ¼
            self.console.print()
            self.console.print(table)
            self.console.print()
        else:
            # åˆ›å»ºåˆ†éš”çº¿
            separator = "=" * 80

            # æ‰“å°æ‘˜è¦
            print(f"\n{separator}")
            print(f"ğŸ“Š è®­ç»ƒæ‘˜è¦ - Epoch {epoch + 1}/{self.args.epochs}")
            print(f"{separator}")

            # æŸå¤±ä¿¡æ¯
            print(f"ğŸ“‰ æŸå¤±ç»Ÿè®¡:")
            print(f"   ç”Ÿæˆå™¨å¹³å‡æŸå¤±: {avg_gen_loss:.6f}")
            print(f"   åˆ¤åˆ«å™¨å¹³å‡æŸå¤±: {avg_dis_loss:.6f}")

            # å­¦ä¹ ç‡ä¿¡æ¯
            print(f"ğŸ” å­¦ä¹ ç‡:")
            if hasattr(self, 'g_optimizer') and self.g_optimizer is not None:
                g_lr = self.g_optimizer.param_groups[0]['lr']
                print(f"   ç”Ÿæˆå™¨: {g_lr:.6f}")
            if hasattr(self, 'd_optimizer') and self.d_optimizer is not None:
                d_lr = self.d_optimizer.param_groups[0]['lr']
                print(f"   åˆ¤åˆ«å™¨/è¯„è®ºå™¨: {d_lr:.6f}")

            # å…¶ä»–æŒ‡æ ‡
            if metrics:
                print(f"ğŸ“ˆ å…¶ä»–æŒ‡æ ‡:")
                for key, value in metrics.items():
                    print(f"   {key}: {value}")

            # å†…å­˜ä½¿ç”¨æƒ…å†µ
            if torch.cuda.is_available():
                print(f"ğŸ’¾ GPU å†…å­˜:")
                print(
                    f"   å·²åˆ†é…: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
                print(
                    f"   ç¼“å­˜: {torch.cuda.memory_reserved() / 1024**2:.2f} MB")
                print(
                    f"   æœ€å¤§åˆ†é…: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB")

            print(f"{separator}\n")

    def train_epoch(self):
        raise NotImplementedError

    def train(self):
        set_random_seed(
            self.args.seed, deterministic=self.args.deterministic, benchmark=self.args.benchmark)
        self.load_checkpoint()

        stop_training = False
        while self.epoch < self.args.epochs and not stop_training:
            # è®­ç»ƒä¸€ä¸ªepoch
            self.train_epoch()

            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler_g.step()
            if self.scheduler_d is not None:
                self.scheduler_d.step()
            # å®šæœŸè¯„ä¼°æ¨¡å‹
            if ((self.epoch + 1) % self.eval_interval == 0) and \
                    ((self.epoch + 1) >= self.eval_interval):
                stop_training = self.evaluate_model()

            # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
            self.save_checkpoint()

            self.epoch += 1

        self.log.close()
        self.log_message(f"Training completed after {self.epoch} epochs.")

    def _apply_spectral_norm(self, model):
        """å¯¹æ¨¡å‹ä¸­çš„å·ç§¯å±‚åº”ç”¨è°±å½’ä¸€åŒ–"""
        for name, module in model.named_modules():
            if isinstance(module, nn.Conv2d):
                spectral_norm(module)

    def add_noise_to_input(self, tensor, noise_factor=None):
        """æ·»åŠ é«˜æ–¯å™ªå£°åˆ°è¾“å…¥ - ä¼˜åŒ–ç‰ˆæœ¬"""
        if noise_factor is None:
            # ä½¿ç”¨é»˜è®¤å™ªå£°å› å­
            noise_factor = getattr(self.args, 'noise_factor', 0.05)

        # å¦‚æœå™ªå£°å› å­ä¸º0ï¼Œç›´æ¥è¿”å›åŸå§‹å¼ é‡
        if noise_factor <= 0:
            return tensor

        # æ‰¹é‡åˆ›å»ºå™ªå£°å¼ é‡ä»¥æé«˜æ•ˆç‡
        noise = torch.randn_like(tensor) * noise_factor

        # æ·»åŠ å™ªå£°ï¼ˆä¿æŒåœ¨åˆç†èŒƒå›´å†…ï¼‰
        noisy_tensor = tensor + noise

        # ç¡®ä¿å€¼åœ¨[0,1]èŒƒå›´
        return torch.clamp(noisy_tensor, 0.0, 1.0)

    def _initialize_weights(self, model):
        """åˆå§‹åŒ–æ¨¡å‹æƒé‡ï¼Œä½¿ç”¨Kaimingåˆå§‹åŒ–"""
        for m in model.modules():
            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):
                nn.init.kaiming_normal_(
                    m.weight, mode='fan_out', nonlinearity='leaky_relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm, nn.LayerNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def _check_nan_values(self, loss_value, model_name):
        """æ£€æŸ¥NaNå€¼å¹¶å¤„ç†"""
        if torch.isnan(loss_value).any() or torch.isinf(loss_value).any():
            self.nan_detected = True
            self.nan_count += 1
            self.log_message(f"è­¦å‘Š: æ£€æµ‹åˆ°NaN/Infå€¼åœ¨{model_name}æŸå¤±ä¸­ï¼Œå°è¯•æ¢å¤è®­ç»ƒ...")

            # å¦‚æœè¿ç»­å¤šæ¬¡æ£€æµ‹åˆ°NaNï¼Œé™ä½å­¦ä¹ ç‡
            if self.nan_count >= self.max_nan_count:
                self.log_message(f"è¿ç»­{self.max_nan_count}æ¬¡æ£€æµ‹åˆ°NaNï¼Œé™ä½å­¦ä¹ ç‡...")
                for param_group in self.g_optimizer.param_groups:
                    param_group['lr'] *= 0.5
                if self.d_optimizer is not None:
                    for param_group in self.d_optimizer.param_groups:
                        param_group['lr'] *= 0.5
                self.nan_count = 0

            return True
        else:
            self.nan_detected = False
            self.nan_count = 0
            return False


class StandardGANTrainer(BaseTrainer):

    def __init__(self, args, generator, discriminator):
        super().__init__(args, generator, discriminator=discriminator)
        if discriminator is None:
            raise ValueError("Discriminator model is not initialized.")
        # ä½¿ç”¨ BCEWithLogitsLoss ä»¥å…¼å®¹ autocast
        self.d_loss = nn.BCEWithLogitsLoss().to(self.device)

        # æ·»åŠ æ¢¯åº¦ç¼©æ”¾å› å­ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        self.gradient_scale = 0.1

        # æ·»åŠ å­¦ä¹ ç‡è°ƒæ•´å› å­
        self.lr_decay_factor = 0.5
        self.lr_decay_patience = 5
        self.lr_decay_counter = 0

        # æ·»åŠ æ¢¯åº¦è£å‰ªå€¼
        self.grad_clip_discriminator = 0.5
        self.grad_clip_generator = 1.0

    def compute_generator_loss(self, fake_outputs, fake_images, real_images):
        """è®¡ç®—ç”Ÿæˆå™¨æŸå¤± - ç®€åŒ–ç‰ˆæœ¬"""
        # å¯¹æŠ—æŸå¤± - å¸Œæœ›åˆ¤åˆ«å™¨å°†ç”Ÿæˆçš„å›¾åƒè¯†åˆ«ä¸ºçœŸå®å›¾åƒ
        adv_loss = self.d_loss(fake_outputs, torch.ones_like(fake_outputs))

        # åƒç´ çº§æŸå¤± - ç”Ÿæˆçš„å›¾åƒåº”è¯¥ä¸çœŸå®å›¾åƒç›¸ä¼¼
        pixel_loss = self.stable_loss(fake_images, real_images)

        # æ€»æŸå¤± = å¯¹æŠ—æŸå¤± + åŠ æƒåƒç´ æŸå¤±
        total_loss = adv_loss + pixel_loss * self.pixel_loss_weight

        return total_loss

    def train_epoch(self):
        if self.discriminator is None:
            self.log_message(
                "Discriminator is not initialized. Cannot train GAN.")
            return

        self.discriminator.train()
        self.generator.train()
        source_g = [0.]
        d_g_z2 = 0.
        gen_loss = []
        dis_loss = []

        # ä½¿ç”¨ rich è¿›åº¦æ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        progress = None
        task_id = None
        if hasattr(self, 'rich_available') and self.rich_available:
            progress = self.create_rich_progress()
            if progress is not None:
                task_id = progress.add_task(f"[cyan]Epoch {self.epoch + 1}/{self.args.epochs}",
                                            total=len(self.train_loader))
                progress.start()
        else:
            # ç¾åŒ–è¿›åº¦æ¡
            pbar = tqdm(enumerate(self.train_loader),
                        total=len(self.train_loader),
                        bar_format='{l_bar}{bar:10}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',
                        colour='green',
                        ncols=100)

        # æ¢¯åº¦ç´¯ç§¯ç›¸å…³å˜é‡
        d_loss_accumulator = 0
        g_loss_accumulator = 0
        batch_count = 0

        for i, (low_images, high_images) in enumerate(self.train_loader):
            batch_count += 1
            low_images = low_images.to(self.device)
            high_images = high_images.to(self.device)
            # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ - ä½¿ç”¨æ­£ç¡®çš„autocast
            with autocast(enabled=self.args.amp):
                # è®­ç»ƒåˆ¤åˆ«å™¨
                self.d_optimizer.zero_grad()
                for j in range(self.args.d_steps):
                    # ç”Ÿæˆå‡å›¾åƒ
                    with torch.no_grad():
                        fake = self.generator(low_images)
                    # åˆ¤åˆ«å™¨å¯¹å‡å›¾åƒçš„åˆ¤æ–­
                    fake_inputs = self.discriminator(fake)
                    # åˆ¤åˆ«å™¨å¯¹çœŸå›¾åƒçš„åˆ¤æ–­
                    real_inputs = self.discriminator(high_images)

                    # åˆ›å»ºæ ‡ç­¾ - ä½¿ç”¨æ ‡ç­¾å¹³æ»‘
                    real_label = torch.ones_like(fake_inputs, requires_grad=False) * (1 - self.label_smoothing) + \
                        torch.rand_like(fake_inputs) * self.label_smoothing
                    fake_label = torch.zeros_like(fake_inputs, requires_grad=False) + \
                        torch.rand_like(fake_inputs) * self.label_smoothing

                    # è®¡ç®—åˆ¤åˆ«å™¨æŸå¤±
                    d_real_output = self.d_loss(real_inputs, real_label)
                    d_x = real_inputs.mean().item()

                    d_fake_output = self.d_loss(fake_inputs, fake_label)
                    d_g_z1 = fake_inputs.mean().item()

                    # æ€»åˆ¤åˆ«å™¨æŸå¤± - ç®€åŒ–ç‰ˆæœ¬
                    d_output = (d_real_output + d_fake_output) / 2.0

                    d_loss_accumulator += d_output.item()

                    # åå‘ä¼ æ’­
                    d_output.backward()
                    self.d_optimizer.step()

                # è®­ç»ƒç”Ÿæˆå™¨
                self.g_optimizer.zero_grad()
                # é‡æ–°ç”Ÿæˆå‡å›¾åƒï¼ˆå› ä¸ºéœ€è¦æ¢¯åº¦ï¼‰
                fake = self.generator(low_images)

                # åˆ¤åˆ«å™¨å¯¹æ–°ç”Ÿæˆçš„å‡å›¾åƒçš„åˆ¤æ–­
                fake_inputs = self.discriminator(fake)

                # è®¡ç®—ç”Ÿæˆå™¨æŸå¤± - ä½¿ç”¨ç®€åŒ–çš„æŸå¤±è®¡ç®—å‡½æ•°
                g_output = self.compute_generator_loss(
                    fake_inputs, fake, high_images)

                g_loss_accumulator += g_output.item()

                d_g_z2 = fake_inputs.mean().item()

                # ä½¿ç”¨scalerè¿›è¡Œåå‘ä¼ æ’­
                g_output.backward()
                self.g_optimizer.step()

                # æ¢¯åº¦ç´¯ç§¯
                if batch_count % self.grad_accum_steps == 0 or i == len(self.train_loader) - 1:
                    # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
                    torch.nn.utils.clip_grad_norm_(
                        self.generator.parameters(), self.grad_clip_generator)
                    # è®°å½•æŸå¤±
                    gen_loss.append(g_loss_accumulator / self.grad_accum_steps)
                    dis_loss.append(d_loss_accumulator / self.grad_accum_steps)

                    # é‡ç½®ç´¯ç§¯å™¨
                    g_loss_accumulator = 0
                    d_loss_accumulator = 0
                    batch_count = 0

                source_g.append(d_g_z2)

                # æ›´æ–°è¿›åº¦æ¡æè¿°
                if hasattr(self,
                           'rich_available') and self.rich_available and progress is not None and task_id is not None:
                    epoch_info = f"Epoch: [{self.epoch + 1}/{self.args.epochs}]"
                    batch_info = f"Batch: [{i + 1}/{len(self.train_loader)}]"
                    loss_info = f"D: {d_output.item():.4f} | G: {g_output.item():.4f}"
                    metrics = f"D(x): {d_x:.3f} | D(G(z)): {d_g_z2:.3f}"

                    # å®‰å…¨è·å–å­¦ä¹ ç‡
                    lr_g = self.g_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'g_optimizer') and self.g_optimizer is not None else 0
                    lr_d = self.d_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'd_optimizer') and self.d_optimizer is not None else 0
                    lr_info = f"lr_G: {lr_g:.6f} | lr_D: {lr_d:.6f}"

                    progress.update(
                        task_id,
                        advance=1,
                        description=f"[cyan]{epoch_info} | {batch_info} | {loss_info} | {metrics} | {lr_info}")
                else:
                    epoch_info = f"Epoch: [{self.epoch + 1}/{self.args.epochs}]"
                    batch_info = f"Batch: [{i + 1}/{len(self.train_loader)}]"
                    loss_info = f"D: {d_output.item():.4f} | G: {g_output.item():.4f}"
                    metrics = f"D(x): {d_x:.3f} | D(G(z)): {d_g_z2:.3f}"

                    # æ·»åŠ å­¦ä¹ ç‡ä¿¡æ¯
                    lr_g = self.g_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'g_optimizer') and self.g_optimizer is not None else 0
                    lr_d = self.d_optimizer.param_groups[0]['lr'] if hasattr(
                        self, 'd_optimizer') and self.d_optimizer is not None else 0
                    lr_info = f"lr_G: {lr_g:.6f} | lr_D: {lr_d:.6f}"

                    if 'pbar' in locals():
                        pbar.set_description(
                            f"ğŸ”„ {epoch_info} | {batch_info} | ğŸ“‰ {loss_info} | ğŸ“Š {metrics} | ğŸ” {lr_info}")

                # æ¯ä¸ªepochç»“æŸæ—¶ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œè€Œä¸æ˜¯æ¯ä¸ªbatch
                if i == len(self.train_loader) - 1:
                    self.save_checkpoint()

        # å…³é—­è¿›åº¦æ¡
        if hasattr(self, 'rich_available') and self.rich_available and progress is not None:
            progress.stop()
        elif 'pbar' in locals():
            pbar.close()

        # è®°å½•è®­ç»ƒæ—¥å¿—
        self.write_log(self.epoch, gen_loss, dis_loss, d_x, d_g_z1, d_g_z2)

        # æ‰“å°è®­ç»ƒæ‘˜è¦
        metrics = {"D(x)": d_x, "D(G(z))": d_g_z2, "PSNR": self.evaluate_model(
        ) if self.epoch % 5 == 0 else "æœªè®¡ç®—"}
        self.print_epoch_summary(self.epoch, gen_loss, dis_loss, metrics)

        # å¯è§†åŒ–ç»“æœ
        self.visualize_results(self.epoch, gen_loss,
                               dis_loss, high_images, low_images, fake)


class WGAN_GPTrainer(BaseTrainer):

    def __init__(self, args, generator, critic):
        super().__init__(args, generator, critic=critic)
        self.lambda_gp = 10
        if self.critic is None:
            raise ValueError("Critic model is not initialized.")

        # ä½¿ç”¨è‡ªå®šä¹‰ä¼˜åŒ–å™¨
        self.c_optimizer, self.g_optimizer = self._get_wgan_optimizers(args)

        # æ·»åŠ  L1 æŸå¤±ç”¨äºåƒç´ çº§ç›‘ç£
        self.l1_loss = nn.L1Loss().to(self.device)

    def _get_wgan_optimizers(self, args):
        """è·å– WGAN ä¸“ç”¨ä¼˜åŒ–å™¨"""
        # ç”Ÿæˆå™¨ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
        g_lr = args.lr * 0.5
        # è¯„è®ºå™¨ä½¿ç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡ (TTUR)
        c_lr = args.lr * 2.0

        # ä¸ºç”Ÿæˆå™¨ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼Œè¾ƒå°çš„ beta å€¼
        g_optimizer = torch.optim.Adam(self.generator.parameters(),
                                       lr=g_lr,
                                       betas=(0.5, 0.999),
                                       weight_decay=args.weight_decay if hasattr(args, 'weight_decay') else 1e-5)

        # ä¸ºè¯„è®ºå™¨ä½¿ç”¨ RMSprop ä¼˜åŒ–å™¨ï¼Œæ›´ç¨³å®š
        c_optimizer = None
        if self.critic is not None:
            c_optimizer = torch.optim.RMSprop(self.critic.parameters(),
                                              lr=c_lr,
                                              weight_decay=args.weight_decay if hasattr(args, 'weight_decay') else 1e-5)

        return c_optimizer, g_optimizer

    def compute_generator_loss(self, critic_fake, fake_images, real_images):
        """è®¡ç®—ç”Ÿæˆå™¨æŸå¤± - ç®€åŒ–ç‰ˆæœ¬"""
        # å¯¹æŠ—æŸå¤± - å¸Œæœ›è¯„è®ºå™¨ç»™ç”Ÿæˆçš„å›¾åƒé«˜åˆ†
        adv_loss = -torch.mean(critic_fake)

        # åƒç´ çº§æŸå¤± - ç”Ÿæˆçš„å›¾åƒåº”è¯¥ä¸çœŸå®å›¾åƒç›¸ä¼¼
        pixel_loss = self.l1_loss(fake_images, real_images)

        # æ€»æŸå¤± = å¯¹æŠ—æŸå¤± + åŠ æƒåƒç´ æŸå¤± + åŠ æƒæ„ŸçŸ¥æŸå¤±
        total_loss = adv_loss + pixel_loss * self.pixel_loss_weight
        return total_loss

    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªå‘¨æœŸ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œç®€åŒ–é€»è¾‘ï¼Œæé«˜æ•ˆç‡"""
        # ä½¿ç”¨richè¿›åº¦æ¡æ˜¾ç¤ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        progress = self.create_rich_progress()
        task_id = None

        # è®°å½•è®­ç»ƒæŸå¤±
        gen_loss = []
        critic_loss = []
        g_z_value = 0.0

        # è®¾ç½®è‡ªåŠ¨æ··åˆç²¾åº¦ä¸Šä¸‹æ–‡
        scaler_g = torch.cuda.amp.GradScaler(enabled=self.args.amp)
        scaler_c = torch.cuda.amp.GradScaler(enabled=self.args.amp)

        # æ¢¯åº¦ç´¯ç§¯è®¡æ•°å™¨
        batch_count = 0

        # é¢„å…ˆå®šä¹‰å™ªå£°ç³»æ•°ä»¥å‡å°‘è®¡ç®—
        noise_factor = self.args.noise_factor if hasattr(
            self.args, 'noise_factor') else 0.05

        # åˆå§‹åŒ–è¿›åº¦æ¡
        if hasattr(self, 'rich_available') and self.rich_available:
            if progress is not None:
                task_id = progress.add_task(f"[cyan]Epoch {self.epoch + 1}/{self.args.epochs}",
                                            total=len(self.train_loader))
                progress.start()
        else:
            pbar = tqdm(enumerate(self.train_loader),
                        total=len(self.train_loader),
                        bar_format='{l_bar}{bar:10}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',
                        colour='blue',
                        ncols=100)

        # å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
        self.generator.train()
        if self.critic is not None:
            self.critic.train()

        # éå†æ•°æ®æ‰¹æ¬¡
        for i, (high_images, low_images) in enumerate(self.train_loader):
            batch_count += 1

            # å°†å›¾åƒç§»åŠ¨åˆ°è®¾å¤‡
            high_images = high_images.to(self.device)
            low_images = low_images.to(self.device)

            # ============================
            # è®­ç»ƒè¯„è®ºå™¨ï¼ˆCriticï¼‰
            # ============================
            critic_loss_batch = 0

            # ä»…å½“criticå­˜åœ¨ä¸”ä¼˜åŒ–å™¨å·²é…ç½®æ—¶æ‰è®­ç»ƒcritic
            if self.critic is not None and self.c_optimizer is not None:
                for j in range(self.d_updates_per_g):  # è¯„è®ºå™¨å¤šæ¬¡æ›´æ–°
                    self.c_optimizer.zero_grad(set_to_none=True)

                    with autocast(enabled=self.args.amp):
                        # ç”Ÿæˆå‡å›¾åƒï¼ˆä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼‰
                        with torch.no_grad():
                            fake_images = self.generator(low_images)

                        # ä¸ºçœŸå‡å›¾åƒå¢åŠ å™ªå£°ï¼ˆæ‰¹é‡å¤„ç†ï¼‰
                        real_with_noise = high_images + \
                            torch.randn_like(high_images) * noise_factor
                        fake_with_noise = fake_images.detach() + torch.randn_like(fake_images) * noise_factor

                        # è®¡ç®—criticè¾“å‡º
                        critic_real = self.critic(real_with_noise)
                        critic_fake = self.critic(fake_with_noise)

                        # è®¡ç®—Wassersteinè·ç¦»å’Œæ¢¯åº¦æƒ©ç½š
                        wasserstein_distance = torch.mean(
                            critic_real) - torch.mean(critic_fake)
                        gradient_penalty = compute_gradient_penalty(self.critic, real_with_noise, fake_with_noise,
                                                                    self.lambda_gp)

                        # è®¡ç®—æ€»criticæŸå¤±
                        loss_critic = -wasserstein_distance + self.lambda_gp * gradient_penalty

                    # ä½¿ç”¨scalerå¤„ç†åå‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰
                    scaler_c.scale(loss_critic).backward()

                    # è®°å½•æŸå¤±å€¼
                    critic_loss_batch = loss_critic.item()
                    critic_loss.append(critic_loss_batch)

                    # åº”ç”¨æ¢¯åº¦è£å‰ªå¹¶æ›´æ–°å‚æ•°
                    if (j == self.d_updates_per_g - 1) and (batch_count % self.grad_accum_steps == 0
                                                            or i == len(self.train_loader) - 1):
                        scaler_c.unscale_(self.c_optimizer)
                        torch.nn.utils.clip_grad_norm_(
                            self.critic.parameters(), 1.0)
                        scaler_c.step(self.c_optimizer)
                        scaler_c.update()

            # ============================
            # è®­ç»ƒç”Ÿæˆå™¨ï¼ˆGeneratorï¼‰
            # ============================
            # æ¸…ç©ºç”Ÿæˆå™¨æ¢¯åº¦
            self.g_optimizer.zero_grad(set_to_none=True)

            with autocast(enabled=self.args.amp):
                # ç”Ÿæˆå‡å›¾åƒ
                fake_images = self.generator(low_images)

                # è®¡ç®—ç”Ÿæˆå™¨æŸå¤±
                if self.critic is not None:
                    # ä½¿ç”¨WGAN-GPçš„ç”Ÿæˆå™¨æŸå¤±ï¼ˆæ— éœ€æ·»åŠ å™ªå£°ï¼Œå› ä¸ºæˆ‘ä»¬å¸Œæœ›æœ€å¤§åŒ–criticå¾—åˆ†ï¼‰
                    critic_fake = self.critic(fake_images)

                    # è®¡ç®—WGANç”Ÿæˆå™¨æŸå¤±
                    # å¸Œæœ›æœ€å¤§åŒ–criticå¯¹å‡å›¾åƒçš„è¯„åˆ†
                    loss_generator = -torch.mean(critic_fake)

                    # è®°å½•G(z)å€¼ç”¨äºç›‘æ§
                    g_z_value = torch.mean(critic_fake).item()
                else:
                    # è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºWGAN_GPTraineråº”è¯¥æ€»æ˜¯æœ‰critic
                    loss_generator = torch.tensor(0.0, device=self.device)

                # æ·»åŠ å†…å®¹æŸå¤±ï¼ˆL1æŸå¤±ï¼‰ï¼Œå¦‚æœå¯ç”¨
                if hasattr(self, 'content_weight') and self.content_weight > 0:
                    content_loss = F.l1_loss(fake_images, high_images)
                    loss_generator = loss_generator + self.content_weight * content_loss

                # æ·»åŠ æ„ŸçŸ¥æŸå¤±ï¼Œå¦‚æœå¯ç”¨
                if hasattr(self, 'perception_weight') and self.perception_weight > 0 and hasattr(
                        self, 'perceptual_loss'):
                    perceptual_loss = self.perceptual_loss(
                        fake_images, high_images)
                    loss_generator = loss_generator + self.perception_weight * perceptual_loss

            # ä½¿ç”¨scalerå¤„ç†åå‘ä¼ æ’­
            scaler_g.scale(loss_generator).backward()

            # è®°å½•æŸå¤±
            gen_loss.append(loss_generator.item())

            # æ¢¯åº¦ç´¯ç§¯å¤„ç†
            if batch_count % self.grad_accum_steps == 0 or i == len(self.train_loader) - 1:
                # æ¢¯åº¦è£å‰ª
                scaler_g.unscale_(self.g_optimizer)
                torch.nn.utils.clip_grad_norm_(
                    self.generator.parameters(), 5.0)
                scaler_g.step(self.g_optimizer)
                scaler_g.update()

            # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
            if self.scheduler_g is not None and batch_count % self.grad_accum_steps == 0:
                self.scheduler_g.step()
            if self.scheduler_d is not None and batch_count % self.grad_accum_steps == 0:
                self.scheduler_d.step()

            # ============================
            # æ›´æ–°è¿›åº¦æ¡
            # ============================
            # ä»…å½“å­˜åœ¨æœ‰æ•ˆæŸå¤±æ—¶æ‰æ›´æ–°è¿›åº¦æ¡
            if len(gen_loss) > 0 and (len(critic_loss) > 0 or self.critic is None):
                # å‡†å¤‡è¿›åº¦æ¡ä¿¡æ¯
                epoch_info = f"Epoch: [{self.epoch + 1}/{self.args.epochs}]"
                batch_info = f"Batch: [{i + 1}/{len(self.train_loader)}]"

                # è·å–æœ€æ–°æŸå¤±
                g_loss_display = gen_loss[-1]
                c_loss_display = critic_loss[-1] if len(
                    critic_loss) > 0 else 0.0

                loss_info = f"C: {c_loss_display:.4f} | G: {g_loss_display:.4f}"
                metrics = f"G(z): {g_z_value:.3f}"

                # è·å–å­¦ä¹ ç‡ä¿¡æ¯
                lr_g = self.g_optimizer.param_groups[0]['lr']
                lr_c = self.c_optimizer.param_groups[0]['lr'] if self.c_optimizer is not None else 0.0
                lr_info = f"lr_G: {lr_g:.6f} | lr_C: {lr_c:.6f}"

                # æ›´æ–°Richè¿›åº¦æ¡æˆ–tqdmè¿›åº¦æ¡
                if hasattr(self,
                           'rich_available') and self.rich_available and progress is not None and task_id is not None:
                    progress.update(
                        task_id,
                        advance=1,
                        description=f"[cyan]{epoch_info} | {batch_info} | {loss_info} | {metrics} | {lr_info}")
                elif 'pbar' in locals():
                    pbar.set_description(
                        f"ğŸ”„ {epoch_info} | {batch_info} | ğŸ“‰ {loss_info} | ğŸ“Š {metrics} | ğŸ” {lr_info}")

        # å…³é—­è¿›åº¦æ¡
        if hasattr(self, 'rich_available') and self.rich_available and progress is not None:
            progress.stop()
        elif 'pbar' in locals():
            pbar.close()

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_gen_loss = np.mean(gen_loss) if gen_loss else 0
        avg_critic_loss = np.mean(critic_loss) if critic_loss else 0

        # æ‰“å°è®­ç»ƒæ‘˜è¦
        self.print_epoch_summary(self.epoch, avg_gen_loss, avg_critic_loss)

        # ä¿å­˜æ£€æŸ¥ç‚¹å’Œå¯è§†åŒ–ç»“æœ
        self.save_checkpoint()

        # å¯è§†åŒ–ç»“æœï¼ˆä½¿ç”¨æœ€åä¸€ä¸ªæ‰¹æ¬¡çš„å›¾åƒï¼‰
        self.visualize_results(
            self.epoch, gen_loss, critic_loss, high_images, low_images, fake_images)

        return avg_gen_loss, avg_critic_loss


def train(args):
    generator = Generator()
    discriminator = Discriminator()
    model_structure(generator, (3, 256, 256))
    model_structure(discriminator, (3, 256, 256))
    trainer = StandardGANTrainer(args, generator, discriminator)
    trainer.train()


def train_WGAN(args):
    generator = Generator()
    critic = Discriminator()
    model_structure(generator, (3, 256, 256))
    model_structure(critic, (3, 256, 256))
    trainer = WGAN_GPTrainer(args, generator, critic)
    trainer.train()


class BasePredictor:

    def __init__(self, args):
        self.args = args
        self.device = torch.device('cpu')
        if args.device == 'cuda':
            self.device = torch.device(
                'cuda:0' if torch.cuda.is_available() else 'cpu')
        self.data = args.data
        self.model = args.model
        self.batch_size = args.batch_size
        self.num_workers = args.num_workers
        self.save_path = args.save_path
        self.generator = Generator(1, 1)
        model_structure(self.generator, (3, 256, 256))
        try:
            # First try loading with weights_only=True (safer)
            checkpoint = torch.load(
                self.model, map_location=self.device, weights_only=True)
        except Exception as e:
            print(
                "Warning: Failed to load with weights_only=True, attempting legacy loading...")
            # If that fails, try the legacy loading method
            checkpoint = torch.load(
                self.model, map_location=self.device, weights_only=False)

        self.generator.load_state_dict(checkpoint['net'])
        self.generator.to(self.device)
        self.generator.eval()
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

    def predict_images(self):
        raise NotImplementedError

    def predict_video(self):
        raise NotImplementedError


class ImagePredictor(BasePredictor):

    def __init__(self, args):
        super().__init__(args)
        self.test_data = LowLightDataset(
            image_dir=self.data, transform=self.transform, phase="test")
        self.test_loader = DataLoader(self.test_data,
                                      batch_size=self.batch_size,
                                      num_workers=self.num_workers,
                                      drop_last=True)

    def predict_images(self):
        # é˜²æ­¢åŒåè¦†ç›–
        path = save_path(self.save_path, model='predict')
        img_pil = transforms.ToPILImage()
        pbar = tqdm(enumerate(self.test_loader),
                    total=len(self.test_loader),
                    bar_format='{l_bar}{bar:10}| {n_fmt}/{'
                    'total_fmt} {elapsed}')
        torch.no_grad()
        i = 0
        if not os.path.exists(os.path.join(path, 'predictions')):
            os.makedirs(os.path.join(path, 'predictions'))
        for i, (low_images, high_images) in pbar:
            lamb = 255.  # å–ç»å¯¹å€¼æœ€å¤§å€¼ï¼Œé¿å…è´Ÿæ•°è¶…å‡ºç´¢å¼•
            low_images = low_images.to(self.device) / lamb
            high_images = high_images.to(self.device) / lamb

            fake = self.generator(low_images)
            for j in range(self.batch_size):
                fake_img = np.array(img_pil(fake[j]), dtype=np.float32)

                if i > 10 and i % 10 == 0:  # å›¾ç‰‡å¤ªå¤šï¼Œåè½®ä¿å­˜ä¸€æ¬¡
                    img_save_path = os.path.join(
                        path, 'predictions', str(i) + '.jpg')
                    cv2.imwrite(img_save_path, fake_img)
                i = i + 1
            pbar.set_description('Processed %d images' % i)
        pbar.close()

    def predict_video(self):
        raise NotImplementedError  # è¯¥ç±»ä¸æ”¯æŒè§†é¢‘é¢„æµ‹


class VideoPredictor(BasePredictor):

    def __init__(self, args):
        super().__init__(args)
        self.video = args.video
        self.save_video = args.save_video

    def predict_images(self):
        raise NotImplementedError  # è¯¥ç±»ä¸æ”¯æŒå›¾ç‰‡é¢„æµ‹

    def predict_video(self):
        print('running on the device: ', self.device)

        try:
            # ä½¿ç”¨ OpenCV æ‰“å¼€è§†é¢‘ï¼Œé¿å… imageio çš„è¿­ä»£é—®é¢˜
            cap = cv2.VideoCapture(self.data)
            if not cap.isOpened():
                print(f"Error: Could not open video {self.data}")
                return

            # è·å–è§†é¢‘å±æ€§
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

            print(
                f"Video properties: {width}x{height}, {fps} FPS, {total_frames} frames")
        except Exception as e:
            print(f"Error opening video: {e}")
            return  # é€€å‡ºå‡½æ•°

        # è®¾ç½®è§†é¢‘å†™å…¥å™¨
        writer = None
        if self.save_video:
            output_path = os.path.join(self.save_path, 'fake.mp4')
            try:
                # ä½¿ç”¨OpenCVçš„VideoWriter
                # ä½¿ç”¨æ•´æ•°å½¢å¼çš„fourccä»£ç ï¼Œé¿å…ä½¿ç”¨VideoWriter_fourcc
                fourcc = int(cv2.VideoWriter.fourcc(
                    'M', 'P', '4', 'V'))  # MP4Vç¼–ç 
                writer = cv2.VideoWriter(output_path, fourcc, fps, (640, 480))

                if not writer.isOpened():
                    print("Error: Could not create video writer")
                    writer = None
            except Exception as e:
                print(f"Error creating video writer: {e}")
                writer = None

        # åˆ›å»ºä¿å­˜ç›®å½•
        if not os.path.exists(os.path.join(self.save_path, 'predictions')):
            os.makedirs(os.path.join(self.save_path, 'predictions'))

        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç¡®ä¿ no_grad çŠ¶æ€æ­£ç¡®ç®¡ç†
        with torch.no_grad():
            frame_count = 0
            pbar = tqdm(total=total_frames, desc="Processing video frames")

            try:
                while True:
                    # è¯»å–ä¸€å¸§
                    ret, frame = cap.read()
                    if not ret:
                        break  # è§†é¢‘ç»“æŸ

                    # è§†é¢‘å¸§å¤„ç†
                    frame_resized = cv2.resize(frame, (640, 480))
                    frame_pil = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
                    frame_tensor = torch.tensor(np.array(frame_pil, np.float32) / 255.,
                                                dtype=torch.float32).to(self.device)
                    frame_tensor = frame_tensor.permute(
                        2, 0, 1).unsqueeze(0)  # [1, 3, 480, 640]

                    # ç”Ÿæˆå¢å¼ºå›¾åƒ
                    fake = self.generator(frame_tensor)
                    fake_np = fake.squeeze(0).permute(
                        1, 2, 0).cpu().detach().numpy()

                    # è½¬æ¢ä¸ºæ˜¾ç¤ºæ ¼å¼
                    fake_display = (np.clip(fake_np, 0, 1)
                                    * 255).astype(np.uint8)
                    fake_display_bgr = cv2.cvtColor(
                        fake_display, cv2.COLOR_RGB2BGR)

                    # æ˜¾ç¤ºå¸§
                    cv2.imshow('Enhanced', fake_display_bgr)
                    cv2.imshow('Original', frame_resized)

                    # ä¿å­˜è§†é¢‘
                    if self.save_video and writer is not None:
                        writer.write(fake_display_bgr)

                    # æ¯10å¸§ä¿å­˜ä¸€å¼ å›¾ç‰‡
                    if frame_count % 10 == 0:
                        img_save_path = os.path.join(
                            self.save_path, 'predictions', f'frame_{frame_count:04d}.jpg')
                        cv2.imwrite(img_save_path, fake_display_bgr)

                    # æ£€æŸ¥æŒ‰é”®
                    key = cv2.waitKey(1)
                    if key == 27:  # ESCé”®
                        break

                    frame_count += 1
                    pbar.update(1)

            except Exception as e:
                print(f"Error processing video: {e}")

            finally:
                # é‡Šæ”¾èµ„æº
                pbar.close()
                cap.release()
                if writer is not None:
                    writer.release()
                cv2.destroyAllWindows()
                print(f"Processed {frame_count} frames")


def predict(args):
    """é¢„æµ‹å‡½æ•°"""
    if args.mode == 'image':
        predictor = ImagePredictor(args)
        predictor.predict_images()
    elif args.mode == 'video':
        predictor = VideoPredictor(args)
        predictor.predict_video()
    else:
        print("ä¸æ”¯æŒçš„é¢„æµ‹æ¨¡å¼")

    print("é¢„æµ‹å®Œæˆ")


def compute_gradient_penalty(critic, real_samples, fake_samples, lambda_gp=10.0):
    """è®¡ç®—WGAN-GPçš„æ¢¯åº¦æƒ©ç½š - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œå¢åŠ æ•°å€¼ç¨³å®šæ€§å’Œæ•ˆç‡"""
    batch_size = real_samples.size(0)
    device = real_samples.device

    # ä¸ºæ¯ä¸ªæ ·æœ¬ç”Ÿæˆéšæœºæ’å€¼ç³»æ•°
    alpha = torch.rand(batch_size, 1, 1, 1, device=device)

    # åˆ›å»ºçœŸå®æ ·æœ¬å’Œç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„éšæœºæ’å€¼ç‚¹
    interpolates = alpha * real_samples + (1 - alpha) * fake_samples
    interpolates.requires_grad_(True)

    # è¯„ä¼°è¯„è®ºå™¨åœ¨æ’å€¼ç‚¹çš„è¾“å‡º
    critic_interpolates = critic(interpolates)

    # è®¡ç®—ç›¸å¯¹äºæ’å€¼ç‚¹çš„æ¢¯åº¦
    gradients = torch.autograd.grad(outputs=critic_interpolates,
                                    inputs=interpolates,
                                    grad_outputs=torch.ones_like(
                                        critic_interpolates, device=device),
                                    create_graph=True,
                                    retain_graph=True,
                                    only_inputs=True)[0]

    # å±•å¹³å¹¶è®¡ç®—æ¢¯åº¦çš„L2èŒƒæ•°
    gradients = gradients.view(batch_size, -1)
    gradient_norm = torch.sqrt(
        torch.sum(gradients**2, dim=1) + 1e-8)  # æ·»åŠ å°å€¼ä»¥é˜²æ­¢é™¤é›¶

    # è®¡ç®—æ¢¯åº¦æƒ©ç½šï¼š(||âˆ‡D(xÌƒ)||â‚‚ - 1)Â²
    gradient_penalty = ((gradient_norm - 1)**2).mean() * lambda_gp

    return gradient_penalty


# Update the "if __name__ == '__main__':" section to include CUT and FastCUT options
if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--path', type=str, default='runs', help='path')
    parser.add_argument('--mode',
                        type=str,
                        default='gan',
                        choices=['gan', 'wgan', 'fastcut', 'predict'],
                        help='è®­ç»ƒæˆ–é¢„æµ‹æ¨¡å¼é€‰æ‹©: gan, wgan')
    parser.add_argument(
        '--data', default='../datasets/kitti_LOL', type=str, help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--epochs', type=int, default=500, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch-size', type=int, default=8, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--device', default='cuda',
                        help='cudaè®¾å¤‡, ä¾‹å¦‚ 0 æˆ– 0,1,2,3 æˆ– cpu')
    parser.add_argument('--d_steps', type=int, default=5, help='åˆ¤åˆ«å™¨è®­ç»ƒæ¬¡æ•°')
    parser.add_argument('--lr', type=float, default=3.5e-4, help='å­¦ä¹ ç‡')
    parser.add_argument('--optimizer', type=str, default='adam',
                        choices=['adam', 'adamw', 'sgd'], help='ä¼˜åŒ–å™¨ç±»å‹')
    parser.add_argument('--b1', type=float,
                        default=0.5, help='Adamä¼˜åŒ–å™¨beta1')
    parser.add_argument('--b2', type=float,
                        default=0.999, help='Adamä¼˜åŒ–å™¨beta2')
    parser.add_argument('--loss', type=str, default='mse',
                        choices=['mse', 'bceblurwithlogitsloss', 'bce', 'focal'], help='æŸå¤±å‡½æ•°ç±»å‹')
    parser.add_argument('--save-path', type=str,
                        default='runs/', help='æ¨¡å‹ä¿å­˜è·¯å¾„')
    parser.add_argument('--amp', action='store_true', help='å¯ç”¨AMP')
    parser.add_argument('--patience', type=int, default=20, help='æ—©åœè€å¿ƒå€¼')
    parser.add_argument('--resume', type=str, default='',
                        help='æ¢å¤è®­ç»ƒ')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--deterministic', action='store_true', help='å¯ç”¨ç¡®å®šæ€§æ¨¡å¼')
    parser.add_argument('--benchmark', action='store_true', help='å¯ç”¨cudnnåŸºå‡†æµ‹è¯•')
    parser.add_argument('--num-workers', type=int,
                        default=0, help='dataloaderå·¥ä½œçº¿ç¨‹æ•°')
    parser.add_argument('--perceptual-weight', type=float,
                        default=0.0, help='æ„ŸçŸ¥æŸå¤±æƒé‡ï¼Œè®¾ä¸º0ç¦ç”¨')
    parser.add_argument('--identity-weight', type=float,
                        default=0.0, help='èº«ä»½æŸå¤±æƒé‡ï¼Œè®¾ä¸º0ç¦ç”¨')
    parser.add_argument('--content-weight', type=float,
                        default=0.0, help='å†…å®¹æŸå¤±æƒé‡ï¼Œè®¾ä¸º0ç¦ç”¨')
    parser.add_argument('--style-weight', type=float,
                        default=0.0, help='é£æ ¼æŸå¤±æƒé‡ï¼Œè®¾ä¸º0ç¦ç”¨')
    args = parser.parse_args()
    set_random_seed(args.seed, args.deterministic, args.benchmark)

    if args.mode == 'predict':
        predict(args)
    else:
        # Select appropriate training function based on mode and model type
        if args.mode == 'gan':
            train(args)
        elif args.mode == 'wgan':
            train_WGAN(args)
